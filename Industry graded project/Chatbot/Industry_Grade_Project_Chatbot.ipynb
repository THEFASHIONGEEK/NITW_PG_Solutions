{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Industry Grade Project - Chatbot.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx7CCJZKdcC2",
        "colab_type": "text"
      },
      "source": [
        "# Building a Chatbot from Scratch "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsR2PuNPdcC5",
        "colab_type": "text"
      },
      "source": [
        "##### In this project we will build a chatbot from scratch using the corenell University's Movie Dialogue corpus.\n",
        "##### We will be using a deep learning based architecture with the main components as a lstm based encoder and decoder."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7b5o0oxdcC7",
        "colab_type": "code",
        "outputId": "05dcba6d-354a-4b65-b5f1-6cf071473e61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98
        }
      },
      "source": [
        "from keras.models import Model\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.layers import Dense, Input, Embedding\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from collections import Counter\n",
        "import nltk\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will switch to TensorFlow 2.x on the 27th of March, 2020.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now\n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WFN5fXsdcDB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import keras\n",
        "import nltk\n",
        "import numpy\n",
        "import sklearn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1IQF3dSidcDI",
        "colab_type": "text"
      },
      "source": [
        "Please make sure that the version of the respective packages are met to the requirement"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oCL0434GdcDK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert keras.__version__=='2.1.2'\n",
        "assert nltk.__version__=='3.4.1'\n",
        "assert sklearn.__version__=='0.21.2'\n",
        "assert numpy.__version__=='1.12.1'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gv38ReVtdcDO",
        "colab_type": "text"
      },
      "source": [
        "Download the glove model available at https://nlp.stanford.edu/projects/glove/\n",
        "\n",
        "Specification : Twitter (2B tweets, 27B tokens, 1.2M vocab, uncased, 25d, 50d, 100d, & 200d vectors, 1.42 GB download): glove.twitter.27B.zip\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXuwJNpGdcDQ",
        "colab_type": "text"
      },
      "source": [
        "you can download it with 'wget' or can directly put the embedding zip file inside 'embedding_data' folder and unzip it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHx1FnytdcDU",
        "colab_type": "code",
        "outputId": "b928bdc5-4cd6-4378-80fb-dcd2b054d2a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "! curl -O http://downloads.cs.stanford.edu/nlp/data/glove.twitter.27B.zip "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 1449M  100 1449M    0     0  2108k      0  0:11:44  0:11:44 --:--:-- 2039k\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4C-nnEZOpZS5",
        "colab_type": "code",
        "outputId": "4d1bf653-07e1-467b-90ac-a0c78a88c1c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!unzip -q glove.twitter.27B.zip -d embedding_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "replace embedding_data/glove.twitter.27B.25d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_yG4mV2dcDZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "RAND_STATE=np.random.seed(42)\n",
        "BATCH_SIZE = 32\n",
        "NUM_EPOCHS = 10\n",
        "GLOVE_EMBEDDING_SIZE = 100\n",
        "HIDDEN_UNITS = 256\n",
        "MAX_INPUT_SEQ_LENGTH = 40\n",
        "MAX_TARGET_SEQ_LENGTH = 40\n",
        "MAX_VOCAB_SIZE = 10000\n",
        "DATA_SET_NAME = 'cornell'\n",
        "DATA_PATH = './cornell/movie_lines_cleaned.txt'\n",
        "GLOVE_MODEL = \"./embedding_data/glove.twitter.27B.100d.txt\"\n",
        "WHITELIST = 'abcdefghijklmnopqrstuvwxyz1234567890?.,'\n",
        "WEIGHT_FILE_PATH =  DATA_SET_NAME + '/word-glove-weights.h5'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsku9GyddcDe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def in_white_list(_word):\n",
        "  '''Check if the characters in the words are whitelisted'''\n",
        "  for char in _word:\n",
        "      if char in WHITELIST:\n",
        "          return True\n",
        "\n",
        "  return False   "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKA3WnoNdcDk",
        "colab_type": "text"
      },
      "source": [
        "Load the glove word embedding in to a dictionary where the **key** is a unique **word token** and the **value** is a **d** dimension vector "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQ6Q6VpHdcDn",
        "colab_type": "text"
      },
      "source": [
        "# Test-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DtZYF8_dcDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_glove_vector():\n",
        "    _word2embedding = {}\n",
        "    file = open(GLOVE_MODEL, mode='rt', encoding='utf8')\n",
        "    for line in file:\n",
        "        '''write here. write your code to load the data in to the dictionary\n",
        "        make sure the value is a numpy array of size 100\n",
        "        max  3 to 6 lines of code'''\n",
        "        words = line.strip().split()\n",
        "        word = words[0]\n",
        "        embeds = np.array(words[1:], dtype=np.float32)\n",
        "        _word2embedding[word] = embeds        \n",
        "    file.close()\n",
        "    return _word2embedding"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdoRZsWEdcDs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word2embedding = load_glove_vector()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wu1WwP20dcDw",
        "colab_type": "text"
      },
      "source": [
        "# Check-1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xAEwEv8asWWl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert len(word2embedding.keys())==1193513\n",
        "for key in word2embedding.keys():\n",
        "    try:\n",
        "        assert len(word2embedding[key])==100\n",
        "    except AssertionError:\n",
        "        print (key,len(word2embedding[key]))  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mCix18rAdcD7",
        "colab_type": "text"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Ju_acaNsrWO",
        "colab_type": "code",
        "outputId": "2bb135e1-b5c0-40cc-d3e1-e76b65c3bf67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkKBqppEdcD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_counter = Counter()\n",
        "lines = open(DATA_PATH, 'rt', encoding='utf8').read().split('\\n')\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "prev_words = []"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FsdjO_jdcD_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for line in lines:\n",
        "    next_words = [w.lower() for w in nltk.word_tokenize(line)]\n",
        "    if len(next_words) > MAX_TARGET_SEQ_LENGTH:\n",
        "        next_words = next_words[0:MAX_TARGET_SEQ_LENGTH]\n",
        "    if len(prev_words) > 0:\n",
        "        input_texts.append(prev_words)\n",
        "        target_words = next_words[:]\n",
        "        target_words.insert(0, 'start')\n",
        "        target_words.append('end')\n",
        "        for w in target_words:\n",
        "            target_counter[w] += 1\n",
        "        target_texts.append(target_words)\n",
        "    prev_words = next_words"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LcYFBgUIdcEF",
        "colab_type": "text"
      },
      "source": [
        "Filter the conversations till max word length and convert the dialogues pairs into input text and target texts. Put **start** and **end** token to recognise the beginning and end of the sentence token.\n",
        "\n",
        "## Let's see some of the training examples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FiCxfQtBdcEG",
        "colab_type": "code",
        "outputId": "6cd3fad2-3014-4290-e182-db23e1638553",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 227
        }
      },
      "source": [
        "for idx, (input_words, target_words) in enumerate(zip(input_texts, target_texts)):\n",
        "    if idx > 10:\n",
        "        break\n",
        "    print([input_words, target_words])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[['they', 'do', 'not', '!'], ['start', 'they', 'do', 'to', '!', 'end']]\n",
            "[['they', 'do', 'to', '!'], ['start', 'i', 'hope', 'so', '.', 'end']]\n",
            "[['i', 'hope', 'so', '.'], ['start', 'she', 'okay', '?', 'end']]\n",
            "[['she', 'okay', '?'], ['start', 'let', \"'s\", 'go', '.', 'end']]\n",
            "[['let', \"'s\", 'go', '.'], ['start', 'wow', 'end']]\n",
            "[['wow'], ['start', 'okay', '--', 'you', \"'re\", 'gon', 'na', 'need', 'to', 'learn', 'how', 'to', 'lie', '.', 'end']]\n",
            "[['okay', '--', 'you', \"'re\", 'gon', 'na', 'need', 'to', 'learn', 'how', 'to', 'lie', '.'], ['start', 'no', 'end']]\n",
            "[['no'], ['start', 'i', \"'m\", 'kidding', '.', 'you', 'know', 'how', 'sometimes', 'you', 'just', 'become', 'this', '``', 'persona', \"''\", '?', 'and', 'you', 'do', \"n't\", 'know', 'how', 'to', 'quit', '?', 'end']]\n",
            "[['i', \"'m\", 'kidding', '.', 'you', 'know', 'how', 'sometimes', 'you', 'just', 'become', 'this', '``', 'persona', \"''\", '?', 'and', 'you', 'do', \"n't\", 'know', 'how', 'to', 'quit', '?'], ['start', 'like', 'my', 'fear', 'of', 'wearing', 'pastels', '?', 'end']]\n",
            "[['like', 'my', 'fear', 'of', 'wearing', 'pastels', '?'], ['start', 'the', '``', 'real', 'you', \"''\", '.', 'end']]\n",
            "[['the', '``', 'real', 'you', \"''\", '.'], ['start', 'what', 'good', 'stuff', '?', 'end']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ksKxizS6dcEL",
        "colab_type": "text"
      },
      "source": [
        "### Create two dictionaries \n",
        "<ol>\n",
        "<li>target_word2id\n",
        "<li>target_id2word\n",
        "</ol>\n",
        "and save it as NumPy file format in the disk.\n",
        "<p>\n",
        "<strong>NOTE:</strong> The ids should start from 1 beacause <strong>0</strong> is reserved for <strong>'unknown'</strong> tokens.\n",
        "Make sure you cosider only the <strong>most common</strong> tokens with <strong>MAX_VOCAB_SIZE</strong> defined above.\n",
        "\n",
        "Most common refers to tokens with higher frequency. \n",
        "</p>\n",
        "<strong>Help:</strong>\n",
        "<ol>\n",
        "<li>Use the target_counter which have the token counts.  \n",
        "<li>Use target_counter.most_common(MAX_VOCAB_SIZE) to filter common tokens\n",
        "    </ol>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qc6oco8qdcEN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_word2idx = dict()\n",
        "'''create a target word to id dictionary called target_word2idx.\n",
        "2 to 3 lines '''\n",
        "for idx, word in enumerate(target_counter.most_common(MAX_VOCAB_SIZE)):\n",
        "    target_word2idx[word[0]] = idx + 1\n",
        "if 'unk' not in target_word2idx:\n",
        "    target_word2idx['unk'] = 0\n",
        "\n",
        "'''create a target to id dictionary called target_idx2word . Approx ~1 line'''\n",
        "target_idx2word = dict([(idx, word) for word, idx in target_word2idx.items()])\n",
        "\n",
        "num_decoder_tokens = len(target_idx2word)\n",
        "\n",
        "\n",
        "np.save( DATA_SET_NAME + '/word-glove-target-word2idx.npy', target_word2idx)\n",
        "np.save( DATA_SET_NAME + '/word-glove-target-idx2word.npy', target_idx2word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PzuUg4zdcER",
        "colab_type": "text"
      },
      "source": [
        "# Check-2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R7pikaJfdcEU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert len (target_word2idx.keys())==len (target_idx2word.keys())==MAX_VOCAB_SIZE+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mw-Ly2xdcEc",
        "colab_type": "text"
      },
      "source": [
        "# Prepare the input data with embedding\n",
        "The input data is a list of lists \n",
        "<ol>\n",
        "<li> First list is a list of sentences\n",
        "<li> Each sentence is a list of words\n",
        " </ol>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBmG1ea4dcEc",
        "colab_type": "code",
        "outputId": "46a5e218-8922-421a-a4ce-b32764db8259",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "input_texts_word2em = []\n",
        "encoder_max_seq_length = 0\n",
        "decoder_max_seq_length = 0\n",
        "\n",
        "for input_words, target_words in zip(input_texts, target_texts):\n",
        "    encoder_input_wids = []\n",
        "    for w in input_words:\n",
        "        '''enter your code here.\n",
        "        '''\n",
        "        emb = np.zeros(shape=GLOVE_EMBEDDING_SIZE)\n",
        "        if w in word2embedding:\n",
        "            emb = word2embedding[w]\n",
        "        encoder_input_wids.append(emb)\n",
        "    input_texts_word2em.append(encoder_input_wids)\n",
        "    encoder_max_seq_length = max(len(encoder_input_wids), encoder_max_seq_length)\n",
        "    decoder_max_seq_length = max(len(target_words), decoder_max_seq_length)\n",
        "\n",
        "context = dict()\n",
        "context['num_decoder_tokens'] = num_decoder_tokens\n",
        "context['encoder_max_seq_length'] = encoder_max_seq_length\n",
        "context['decoder_max_seq_length'] = decoder_max_seq_length\n",
        "\n",
        "print(context)\n",
        "np.save( DATA_SET_NAME + '/word-glove-context.npy', context)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'num_decoder_tokens': 10001, 'encoder_max_seq_length': 40, 'decoder_max_seq_length': 42}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8IJeZVkdcEg",
        "colab_type": "text"
      },
      "source": [
        "# Check-3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXaPOQlddcEh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for input_text,input_text_embed in zip (input_texts,range(len(input_texts_word2em))):\n",
        "    assert (len(input_text)==len(input_texts_word2em[input_text_embed]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXh-5WEUdcEn",
        "colab_type": "text"
      },
      "source": [
        "# Generate Training data per batch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gvg8LBt-dcEo",
        "colab_type": "text"
      },
      "source": [
        "generate_batch takes input embedding data (input_word2em_data) and target text data (target_texts) and returns trainable X and Y.\n",
        "X is a list of [X1,X2]\n",
        "where \n",
        "X1 is encoder_input_data_batch( which is created by putting the word embedding(glove vector) of the input tokens) padded in to a shape of (BATCH_SIZE, encoder_max_seq_length, GLOVE_EMBEDDING_SIZE)\n",
        "\n",
        "X2 is decoder_input_data_batch which is created by putting the word embedding(glove vector) of the target_words tokens and padding it to a shape of (BATCH_SIZE, encoder_max_seq_length, GLOVE_EMBEDDING_SIZE)\n",
        "\n",
        "Y is decoder_target_data_batch which is in shape of (BATCH_SIZE, decoder_max_seq_length, num_decoder_tokens)\n",
        "which signifies for each target token text  in the batch we have an option of any token from the vocabularu to be the next predicted word "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37R_9qpHdcEp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_batch(input_word2em_data, output_text_data):\n",
        "    num_batches = len(input_word2em_data) // BATCH_SIZE\n",
        "    while True:\n",
        "        for batchIdx in range(0, num_batches):\n",
        "            start = batchIdx * BATCH_SIZE\n",
        "            end = (batchIdx + 1) * BATCH_SIZE\n",
        "            '''Fill your code here. 5 to 10 lines'''\n",
        "            encoder_input_data_batch = pad_sequences(input_word2em_data[start:end], encoder_max_seq_length)\n",
        "            decoder_target_data_batch = np.zeros(shape=(BATCH_SIZE, decoder_max_seq_length, num_decoder_tokens))\n",
        "            decoder_input_data_batch = np.zeros(shape=(BATCH_SIZE, decoder_max_seq_length, GLOVE_EMBEDDING_SIZE))\n",
        "            for lineIdx, target_words in enumerate(output_text_data[start:end]):\n",
        "                for idx, w in enumerate(target_words):\n",
        "                    w2idx = target_word2idx['unknown']  # default unknown\n",
        "                    if w in target_word2idx:\n",
        "                        w2idx = target_word2idx[w]\n",
        "                    if w in word2embedding:\n",
        "                        decoder_input_data_batch[lineIdx, idx, :] = word2embedding[w]\n",
        "                    if idx > 0:\n",
        "                        decoder_target_data_batch[lineIdx, idx - 1, w2idx] = 1            \n",
        "            yield [encoder_input_data_batch, decoder_input_data_batch], decoder_target_data_batch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EGjnjiyidcEt",
        "colab_type": "text"
      },
      "source": [
        "# Check-4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ezag0feRdcEu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Xtrain, Xtest, Ytrain, Ytest = train_test_split(input_texts_word2em, target_texts, test_size=0.2, random_state=42)\n",
        "train_gen = generate_batch(Xtrain, Ytrain)\n",
        "for i,j in train_gen:\n",
        "    assert i[0].shape==(BATCH_SIZE,context['encoder_max_seq_length'],GLOVE_EMBEDDING_SIZE)\n",
        "    assert i[1].shape==(BATCH_SIZE,context['decoder_max_seq_length'],GLOVE_EMBEDDING_SIZE)\n",
        "    assert j.shape==(BATCH_SIZE,context['decoder_max_seq_length'],context['num_decoder_tokens'])\n",
        "\n",
        "print ('Test Case 4 Passes!')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jazC-goddcEx",
        "colab_type": "text"
      },
      "source": [
        "# Model Architecture "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lab5ddRGdcEy",
        "colab_type": "code",
        "outputId": "d714ab20-50ac-459b-f71a-899be270657d",
        "colab": {}
      },
      "source": [
        "from keras.utils import plot_model\n",
        "plot_model(model, to_file='model.png')\n",
        "from IPython.display import Image\n",
        "Image(filename='model.png',height=400,width=400)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": [],
            "image/png": {
              "height": 400,
              "width": 400
            }
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKnqwC4ndcE4",
        "colab_type": "text"
      },
      "source": [
        "# The Model architecture is explined in the diagram above "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8VfVTm4dcE6",
        "colab_type": "text"
      },
      "source": [
        "# Test-5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUJbRP9SdcE8",
        "colab_type": "text"
      },
      "source": [
        "<ol>\n",
        "<li> Step 1: Use a LSTM encoder to get input words encoded in the form of (encoder outputs, encoder hidden state, encoder context) from input words\n",
        "<li> Step 2:  Use a LSTM decoder to get target words encoded in the form of (decoder outputs, decoder hidden state, decoder context) from target words. Use encoder hidden states and encoder context (represents input memory) as initial state .\n",
        "<li> Step 3: Use a dense layer to predict the next token out of the vocabulary given decoder output generated by Step 2.\n",
        "<li> Step 4: Use loss ='categorical_crossentropy' and optimizer='rmsprop'\n",
        "</ol>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU974rtIdcE9",
        "colab_type": "code",
        "outputId": "762821dc-b456-4a28-bd8b-68fba6fd418b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        }
      },
      "source": [
        "'''write your code here.\n",
        "   create a model object'''\n",
        "encoder_inputs = Input(shape=(None, GLOVE_EMBEDDING_SIZE), name='encoder_inputs')\n",
        "encoder_lstm = LSTM(units=HIDDEN_UNITS, return_state=True, name='encoder_lstm')\n",
        "encoder_outputs, encoder_state_h, encoder_state_c = encoder_lstm(encoder_inputs)\n",
        "encoder_states = [encoder_state_h, encoder_state_c]\n",
        "\n",
        "decoder_inputs = Input(shape=(None, GLOVE_EMBEDDING_SIZE), name='decoder_inputs')\n",
        "decoder_lstm = LSTM(units=HIDDEN_UNITS, return_state=True, return_sequences=True, name='decoder_lstm')\n",
        "decoder_outputs, decoder_state_h, decoder_state_c = decoder_lstm(decoder_inputs,\n",
        "                                                                 initial_state=encoder_states)\n",
        "decoder_dense = Dense(units=num_decoder_tokens, activation='softmax', name='decoder_dense')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='rmsprop')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnNAPfQFdcFG",
        "colab_type": "text"
      },
      "source": [
        "# Check-5 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecKi6g5MdcFI",
        "colab_type": "text"
      },
      "source": [
        "Check the model summary should look like this "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2-ZeC66dcFJ",
        "colab_type": "code",
        "outputId": "855dfe46-3a0a-44fc-81aa-26961ec9db9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_inputs (InputLayer)     (None, None, 100)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "decoder_inputs (InputLayer)     (None, None, 100)    0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_lstm (LSTM)             [(None, 256), (None, 365568      encoder_inputs[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "decoder_lstm (LSTM)             [(None, None, 256),  365568      decoder_inputs[0][0]             \n",
            "                                                                 encoder_lstm[0][1]               \n",
            "                                                                 encoder_lstm[0][2]               \n",
            "__________________________________________________________________________________________________\n",
            "decoder_dense (Dense)           (None, None, 10001)  2570257     decoder_lstm[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 3,301,393\n",
            "Trainable params: 3,301,393\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ad4qy3CBxXaV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "json = model.to_json()\n",
        "open( DATA_SET_NAME + '/word-glove-architecture.json', 'w').write(json)\n",
        "\n",
        "train_gen = generate_batch(Xtrain, Ytrain)\n",
        "test_gen = generate_batch(Xtest, Ytest)\n",
        "\n",
        "train_num_batches = len(Xtrain) // BATCH_SIZE\n",
        "test_num_batches = len(Xtest) // BATCH_SIZE\n",
        "\n",
        "checkpoint = ModelCheckpoint(filepath=WEIGHT_FILE_PATH, save_best_only=True)\n",
        "\n",
        "model.fit_generator(generator=train_gen, steps_per_epoch=train_num_batches,\n",
        "                    epochs=NUM_EPOCHS,\n",
        "                    verbose=1, validation_data=test_gen, validation_steps=test_num_batches, callbacks=[checkpoint])\n",
        "\n",
        "model.save_weights(WEIGHT_FILE_PATH)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOTTSdcndcFS",
        "colab_type": "text"
      },
      "source": [
        "# Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FacmG-nTnkqW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CornellWordGloveChatBot(object):\n",
        "    model = None\n",
        "    encoder_model = None\n",
        "    decoder_model = None\n",
        "    target_word2idx = None\n",
        "    target_idx2word = None\n",
        "    max_decoder_seq_length = None\n",
        "    max_encoder_seq_length = None\n",
        "    num_decoder_tokens = None\n",
        "    word2embedding = None\n",
        "\n",
        "    def __init__(self):\n",
        "        self.word2embedding = load_glove_vector()\n",
        "        print(len(self.word2embedding))\n",
        "        print(self.word2embedding['start'])\n",
        "\n",
        "        self.target_word2idx = np.load( DATA_SET_NAME + '/word-glove-target-word2idx.npy',allow_pickle=True).item()\n",
        "        self.target_idx2word = np.load( DATA_SET_NAME + '/word-glove-target-idx2word.npy',allow_pickle=True).item()\n",
        "        context = np.load( DATA_SET_NAME + '/word-glove-context.npy',allow_pickle=True).item()\n",
        "        self.max_encoder_seq_length = context['encoder_max_seq_length']\n",
        "        self.max_decoder_seq_length = context['decoder_max_seq_length']\n",
        "        self.num_decoder_tokens = context['num_decoder_tokens']\n",
        "\n",
        "        encoder_inputs = Input(shape=(None, GLOVE_EMBEDDING_SIZE), name='encoder_inputs')\n",
        "        encoder_lstm = LSTM(units=HIDDEN_UNITS, return_state=True, name=\"encoder_lstm\")\n",
        "        encoder_outputs, encoder_state_h, encoder_state_c = encoder_lstm(encoder_inputs)\n",
        "        encoder_states = [encoder_state_h, encoder_state_c]\n",
        "\n",
        "        decoder_inputs = Input(shape=(None, GLOVE_EMBEDDING_SIZE), name='decoder_inputs')\n",
        "        decoder_lstm = LSTM(units=HIDDEN_UNITS, return_sequences=True, return_state=True, name='decoder_lstm')\n",
        "        decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "        decoder_dense = Dense(self.num_decoder_tokens, activation='softmax', name='decoder_dense')\n",
        "        decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "        self.model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "\n",
        "        self.model.load_weights( DATA_SET_NAME + '/word-glove-weights.h5')\n",
        "        self.model.compile(optimizer='rmsprop', loss='categorical_crossentropy')\n",
        "\n",
        "        self.encoder_model = Model(encoder_inputs, encoder_states)\n",
        "\n",
        "        decoder_state_inputs = [Input(shape=(HIDDEN_UNITS,)), Input(shape=(HIDDEN_UNITS,))]\n",
        "        decoder_outputs, state_h, state_c = decoder_lstm(decoder_inputs, initial_state=decoder_state_inputs)\n",
        "        decoder_states = [state_h, state_c]\n",
        "        decoder_outputs = decoder_dense(decoder_outputs)\n",
        "        self.decoder_model = Model([decoder_inputs] + decoder_state_inputs, [decoder_outputs] + decoder_states)\n",
        "\n",
        "    def reply(self, input_text):\n",
        "        input_seq = []\n",
        "        input_emb = []\n",
        "        for word in nltk.word_tokenize(input_text.lower()):\n",
        "            if not in_white_list(word):\n",
        "                continue\n",
        "            emb = np.zeros(shape=GLOVE_EMBEDDING_SIZE)\n",
        "            if word in self.word2embedding:\n",
        "                emb = self.word2embedding[word]\n",
        "            input_emb.append(emb)\n",
        "        input_seq.append(input_emb)\n",
        "        input_seq = pad_sequences(input_seq, self.max_encoder_seq_length)\n",
        "        states_value = self.encoder_model.predict(input_seq)\n",
        "        target_seq = np.zeros((1, 1, GLOVE_EMBEDDING_SIZE))\n",
        "        target_seq[0, 0, :] = self.word2embedding['start']\n",
        "        target_text = ''\n",
        "        target_text_len = 0\n",
        "        terminated = False\n",
        "        while not terminated:\n",
        "            output_tokens, h, c = self.decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "            sample_token_idx = np.argmax(output_tokens[0, -1, :])\n",
        "            sample_word = self.target_idx2word[sample_token_idx]\n",
        "            target_text_len += 1\n",
        "\n",
        "            if sample_word != 'start' and sample_word != 'end':\n",
        "                target_text += ' ' + sample_word\n",
        "\n",
        "            if sample_word == 'end' or target_text_len >= self.max_decoder_seq_length:\n",
        "                terminated = True\n",
        "\n",
        "            target_seq = np.zeros((1, 1, GLOVE_EMBEDDING_SIZE))\n",
        "            if sample_word in self.word2embedding:\n",
        "                target_seq[0, 0, :] = self.word2embedding[sample_word]\n",
        "\n",
        "            states_value = [h, c]\n",
        "        return target_text.strip()\n",
        "\n",
        "    def test_run(self):\n",
        "        print(self.reply('Hello'))\n",
        "        print(self.reply('How are you doing?'))\n",
        "        print(self.reply('Have you heard the news?'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkuSiYWi10kH",
        "colab_type": "code",
        "outputId": "6c86f7b5-4de5-49a7-867b-f79c03eb3269",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        }
      },
      "source": [
        "model = CornellWordGloveChatBot()\n",
        "model.test_run()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1193514\n",
            "[-0.17989   0.22297   0.47938  -0.71227  -0.45818   1.0285    0.32394\n",
            " -0.060409 -0.37064   0.3051   -0.14261  -0.56449  -4.5301    0.54817\n",
            " -0.85281  -0.086907 -0.28587   0.86288  -0.28724  -0.65113  -0.97384\n",
            "  0.11036  -0.05808  -0.034859 -0.36309   0.19478   0.17636  -0.32154\n",
            " -0.22864  -0.11961  -0.044675  0.54424  -0.25474   0.21692   0.5004\n",
            "  0.21677   0.33958  -0.27821   0.58674   0.013013 -0.98293   0.5214\n",
            "  0.11687  -0.10702   0.1903    0.25038  -0.24482  -0.068194 -0.23054\n",
            "  0.24936   0.081091 -0.71015   0.050871 -0.16209   0.49785  -0.44498\n",
            " -0.79807  -0.1008    0.80597   0.18716  -0.65218  -0.27916   0.23074\n",
            " -0.35599  -0.18894   0.36532   0.74004  -0.29412   0.90441   0.067676\n",
            " -0.19106   0.59315   0.058992  0.53448   0.32551   0.060201  0.28332\n",
            "  0.026973 -0.079146 -0.40832   1.3507   -0.1911   -0.23131  -0.37369\n",
            "  0.32181   0.10459  -0.11756   0.028256  0.27408  -0.289    -0.21644\n",
            "  0.17697  -0.23683   0.15782  -0.22889   0.26629  -0.28217   0.29003\n",
            " -0.032464 -0.55074 ]\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            ". ! ! ! ! , ! , ! ! ! get get get ! , , , , , honest excuse hang such tunnel consecrate square call\n",
            ". ? ! . ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? . . . . . , , . ,\n",
            ". ? ! . ? ? ? ? . . . . . . . . . . . . . . . . . . . . . . . . . ! in like like like like like like like\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}